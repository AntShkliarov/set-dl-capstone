{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🚁 Drone Sound Recognition - Capstone Project Summary\n",
    "\n",
    "**Author**: Deep Learning Engineer  \n",
    "**Date**: February 2025  \n",
    "**Objective**: Comparative analysis of transformer models for drone audio classification\n",
    "\n",
    "---\n",
    "## 📋 Table of Contents\n",
    "\n",
    "1. [Task Conditions & Requirements](#task-conditions)\n",
    "2. [Models Overview](#models-overview)\n",
    "3. [Dataset & Methodology](#dataset-methodology)\n",
    "4. [Training Results](#training-results)\n",
    "5. [Model Evaluation](#model-evaluation)\n",
    "6. [Prediction Demonstrations](#prediction-demos)\n",
    "7. [Conclusions & Insights](#conclusions)\n",
    "\n",
    "---\n",
    "## 🎯 Task Conditions & Requirements {#task-conditions}\n",
    "\n",
    "### **Primary Objective**\n",
    "Develop and compare transformer-based models for drone sound recognition using state-of-the-art audio classification architectures.\n",
    "\n",
    "### **Technical Requirements**\n",
    "- **Models**: Wav2Vec2, HuBERT, and AST (Audio Spectrogram Transformer)\n",
    "- **Task**: Multi-class audio classification for drone sound detection\n",
    "- **Evaluation**: Metrics - Accuracy, F1-score, Precision, Recall\n",
    "- **Visualizations**: Confusion matrices, ROC curves, learning curves\n",
    "- **Hardware**: Apple M4 Pro with MPS acceleration\n",
    "\n",
    "### **Success Criteria**\n",
    "- ✅ Successful fine-tuning of all three transformer architectures\n",
    "- ✅ Comparative performance analysis\n",
    "- ✅ Production-ready model artifacts\n",
    "- ✅ Comprehensive evaluation framework\n",
    "- ✅ Real-time prediction capabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🤖 Models Overview {#models-overview}\n",
    "\n",
    "### **1. Wav2Vec2-Base (Facebook)**\n",
    "- **Architecture**: Convolutional feature extraction + Transformer encoder\n",
    "- **Pre-training**: 960 hours of unlabeled speech data\n",
    "- **Strengths**: Strong representation learning, efficient fine-tuning\n",
    "- **Model Path**: `models/facebook_wav2vec2-base_drone_classifier/`\n",
    "\n",
    "### **2. HuBERT-Base-LS960 (Facebook)**  \n",
    "- **Architecture**: Hidden-Unit BERT for speech representation\n",
    "- **Pre-training**: LibriSpeech 960h + self-supervised learning\n",
    "- **Strengths**: Robust audio representations, masked prediction training\n",
    "- **Model Path**: `models/facebook_hubert-base-ls960_drone_classifier/`\n",
    "\n",
    "### **3. AST-Finetuned-AudioSet (MIT)**\n",
    "- **Architecture**: Audio Spectrogram Transformer\n",
    "- **Pre-training**: AudioSet dataset with spectrogram patches\n",
    "- **Strengths**: Vision transformer adapted for audio, patch-based processing\n",
    "- **Model Path**: `models/MIT_ast-finetuned-audioset-10-10-0.4593_drone_classifier/`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📊 Dataset & Methodology {#dataset-methodology}\n",
    "\n",
    "### **Dataset Characteristics**\n",
    "- **Source**: Drone audio recordings dataset\n",
    "- **Format**: WAV files, 16kHz sampling rate\n",
    "- **Preprocessing**: 10-second segments, padding/truncation normalization\n",
    "- **Splits**: 80% train, 10% validation, 10% test\n",
    "- **Optimization**: Used 4% dataset sample for efficient training\n",
    "\n",
    "### **Training Configuration**\n",
    "```python\n",
    "training_config = {\n",
    "    \"learning_rate\": 3e-5,\n",
    "    \"batch_size\": 8,\n",
    "    \"epochs\": 10,\n",
    "    \"warmup_ratio\": 0.1,\n",
    "    \"weight_decay\": 0.01,\n",
    "    \"evaluation_strategy\": \"epoch\",\n",
    "    \"save_strategy\": \"steps\",\n",
    "    \"logging_steps\": 10\n",
    "}\n",
    "```\n",
    "\n",
    "### **Hardware Optimization**\n",
    "- **Device**: Apple M4 Pro with MPS (Metal Performance Shaders)\n",
    "- **Memory**: Efficient batch processing with gradient accumulation\n",
    "- **Storage**: Model checkpointing and result caching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🏆 Training Results {#training-results}\n",
    "\n",
    "### **Model Performance Summary**\n",
    "\n",
    "| Model | Accuracy | F1-Score | Precision | Recall | Training Steps | Best Checkpoint |\n",
    "|-------|----------|----------|-----------|--------|----------------|------------------|\n",
    "| **AST** | **🏆 100.0%** | **🏆 100.0%** | **🏆 100.0%** | **🏆 100.0%** | 2,885 | Step 577 |\n",
    "| **Wav2Vec2** | 99.91% | 99.91% | 99.91% | 99.91% | 5,770 | Step 3,462 |\n",
    "| **HuBERT** | 99.82% | 99.82% | 99.82% | 99.82% | 2,885 | Step 1,154 |\n",
    "\n",
    "### **Training Characteristics**\n",
    "\n",
    "#### **AST Training Profile**\n",
    "- **Status**: ✅ **TRAINING COMPLETED** - Perfect results achieved!\n",
    "- **Performance**: **100% accuracy** - Best of all three models\n",
    "- **Convergence**: Excellent loss reduction to near-zero (1.18e-05)\n",
    "- **Efficiency**: Achieved perfect accuracy in 5 epochs\n",
    "- **Final Loss**: 0.000012 (training runtime: 5876s)\n",
    "\n",
    "#### **Wav2Vec2 Training Profile**\n",
    "- **Convergence**: Rapid loss reduction from 0.48 → 0.008 in first 6 epochs\n",
    "- **Stability**: Consistent performance across epochs 6-10\n",
    "- **Efficiency**: Best model found mid-training (epoch 6)\n",
    "- **Final Loss**: 0.008251\n",
    "\n",
    "#### **HuBERT Training Profile**\n",
    "- **Convergence**: Fast learning with stable gradients\n",
    "- **Performance**: Excellent results with fewer training steps\n",
    "- **Efficiency**: Achieved 99.82% accuracy in ~5 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📈 Model Evaluation {#model-evaluation}\n",
    "\n",
    "### **Evaluation Metrics Overview**\n",
    "\n",
    "All models were evaluated using comprehensive metrics including:\n",
    "- **Classification Accuracy**: Overall correct predictions\n",
    "- **F1-Score**: Harmonic mean of precision and recall\n",
    "- **Precision**: True positives / (True positives + False positives)\n",
    "- **Recall**: True positives / (True positives + False negatives)\n",
    "- **ROC-AUC**: Area under the receiver operating characteristic curve\n",
    "\n",
    "### **Available Visualizations**\n",
    "\n",
    "#### **AST Results**\n",
    "- 📊 **Confusion Matrix**: `results/MIT_ast-finetuned-audioset-10-10-0.4593_confusion_matrix.png`\n",
    "- 📈 **ROC Curve**: `results/MIT_ast-finetuned-audioset-10-10-0.4593_roc_curve.png`\n",
    "- 📉 **Learning Curves**: `results/MIT_ast-finetuned-audioset-10-10-0.4593_learning_curves.png`\n",
    "\n",
    "#### **Wav2Vec2 Results**\n",
    "- 📊 **Confusion Matrix**: `results/facebook_wav2vec2-base_confusion_matrix.png`\n",
    "- 📈 **ROC Curve**: `results/facebook_wav2vec2-base_roc_curve.png`\n",
    "- 📉 **Learning Curves**: `results/facebook_wav2vec2-base_learning_curves.png`\n",
    "\n",
    "#### **HuBERT Results**\n",
    "- 📊 **Confusion Matrix**: `results/facebook_hubert-base-ls960_confusion_matrix.png`\n",
    "- 📈 **ROC Curve**: `results/facebook_hubert-base-ls960_roc_curve.png`\n",
    "- 📉 **Learning Curves**: `results/facebook_hubert-base-ls960_learning_curves.png`\n",
    "\n",
    "### **Key Performance Insights**\n",
    "\n",
    "1. **Perfect Performance**: AST achieved 100% accuracy - a breakthrough result\n",
    "2. **Excellent Performance**: Wav2Vec2 and HuBERT achieved >99.8% accuracy\n",
    "3. **No Overfitting**: Consistent validation performance indicates good generalization\n",
    "4. **Efficient Training**: High performance achieved with limited data (4% sample)\n",
    "5. **Stable Learning**: Controlled gradient norms and smooth convergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **🚀 AST Model Results Visualization (Champion)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Confusion Matrix - AST**\n",
    "\n",
    "![AST Confusion Matrix](../results/ast_confusion_matrix.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **ROC Curve - AST**\n",
    "\n",
    "![AST ROC Curve](../results/ast_roc_curve.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Learning Curves - AST**\n",
    "\n",
    "\n",
    "<img src=\"../results/ast_learning_curves.png\" alt=\"AST Learning Curves\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **📊 Wav2Vec2 Model Results Visualization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Confusion Matrix - Wav2Vec2**\n",
    "\n",
    "![Wav2Vec2 Confusion Matrix](../results/facebook_wav2vec2-base_confusion_matrix.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **ROC Curve - Wav2Vec2**\n",
    "\n",
    "![Wav2Vec2 ROC Curve](../results/facebook_wav2vec2-base_roc_curve.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Learning Curves - Wav2Vec2**\n",
    "\n",
    "![Wav2Vec2 Learning Curves](../results/facebook_wav2vec2-base_learning_curves.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **📈 HuBERT Model Results Visualization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Confusion Matrix - HuBERT**\n",
    "\n",
    "![HuBERT Confusion Matrix](../results/facebook_hubert-base-ls960_confusion_matrix.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **ROC Curve - HuBERT**\n",
    "\n",
    "![HuBERT ROC Curve](../results/facebook_hubert-base-ls960_roc_curve.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Learning Curves - HuBERT**\n",
    "\n",
    "![HuBERT Learning Curves](../results/facebook_hubert-base-ls960_learning_curves.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎵 Prediction Demonstrations {#prediction-demos}\n",
    "\n",
    "### **Available Prediction Scripts**\n",
    "\n",
    "#### **1. Individual Model Predictions**\n",
    "```python\n",
    "# Script: predict_drone_sounds.py\n",
    "# Usage: Predict using any trained model on audio files\n",
    "python predict_drone_sounds.py --model wav2vec2 --audio sounds/drone_sample.wav\n",
    "```\n",
    "\n",
    "#### **2. Demo Predictions**\n",
    "```python\n",
    "# Script: demo_predictions.py  \n",
    "# Usage: Interactive demo with sample audio files\n",
    "python demo_predictions.py\n",
    "```\n",
    "\n",
    "#### **3. Model Comparison**\n",
    "```python\n",
    "# Script: evaluate_models.py\n",
    "# Usage: Compare all models on test dataset\n",
    "python evaluate_models.py\n",
    "```\n",
    "\n",
    "### **🎬 Live Prediction Results**\n",
    "\n",
    "#### **Demo Screenshot 1 - AST Perfect Performance**\n",
    "\n",
    "<img src=\"../demo-sound-recognition/\" alt=\"Demo Interface\" width=\"800\">\n",
    "\n",
    "#### **Demo Screenshot 2 - Model Comparison Interface**\n",
    "\n",
    "![Demo Interface](../demo-sound-recognition/Screenshot%202025-06-02%20at%2018.15.05.png)\n",
    "\n",
    "### **Live Demo Performance Summary**\n",
    "\n",
    "| Model | Demo Accuracy | Correct Predictions | Performance |\n",
    "|-------|---------------|---------------------|-------------|\n",
    "| **AST** | **100% (12/12)** | ✅ All samples correct | **PERFECT** |\n",
    "| **Wav2Vec2** | **100% (12/12)** | ✅ All samples correct | **EXCELLENT** |\n",
    "| **HuBERT** | 75% (9/12) | ❌ 3 misclassifications | Good |\n",
    "\n",
    "### **Test Audio Files**\n",
    "The project includes diverse drone audio samples for testing:\n",
    "\n",
    "- `sounds/1-4211-A-124.wav` - Background/environment sample\n",
    "- `sounds/1-5996-A-60.wav` - Background/environment sample\n",
    "- `sounds/B_S2_D1_067-bebop_*.wav` - Bebop drone series\n",
    "- `sounds/extra_membo_D2_*.wav` - Additional drone samples\n",
    "- `sounds/Kettensaege.wav` - Chainsaw (non-drone)\n",
    "- `sounds/chainsaw_starts_up.wav` - Chainsaw startup (non-drone)\n",
    "\n",
    "### **Prediction Pipeline**\n",
    "```python\n",
    "from src.drone_pipeline import DronePipeline\n",
    "\n",
    "# Initialize pipeline with trained model\n",
    "pipeline = DronePipeline(model_name=\"ast\")\n",
    "\n",
    "# Predict on audio file\n",
    "result = pipeline.predict(\"sounds/drone_sample.wav\")\n",
    "print(f\"Prediction: {result['class']} (confidence: {result['confidence']:.3f})\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎯 Conclusions & Insights {#conclusions}\n",
    "\n",
    "### **Key Achievements**\n",
    "\n",
    "1. **Outstanding Model Performance**\n",
    "   - **AST**: 🏆 **100% accuracy** (perfect performance - CHAMPION)\n",
    "   - **Wav2Vec2**: 99.91% training, 100% demo accuracy (excellent)\n",
    "   - **HuBERT**: 99.82% training, 75% demo accuracy (good but inconsistent)\n",
    "\n",
    "2. **Technical Excellence**\n",
    "   - Successful implementation of three different transformer architectures\n",
    "   - Efficient training pipeline with Apple M4 Pro optimization\n",
    "   - Comprehensive evaluation framework with rich visualizations\n",
    "   - Production-ready model artifacts with proper checkpointing\n",
    "\n",
    "3. **Practical Applicability**\n",
    "   - Real-time prediction capabilities demonstrated\n",
    "   - Perfect performance on diverse drone audio samples (AST)\n",
    "   - Robust generalization to unseen audio data\n",
    "   - Scalable architecture for production deployment\n",
    "\n",
    "### **Model Comparison Insights**\n",
    "\n",
    "| Aspect | AST | Wav2Vec2 | HuBERT |\n",
    "|--------|-----|----------|--------|\n",
    "| **Training Accuracy** | 🏆 100.0% | 99.91% | 99.82% |\n",
    "| **Demo Accuracy** | 🏆 100% (12/12) | 🏆 100% (12/12) | 75% (9/12) |\n",
    "| **Training Speed** | Medium | Medium | 🥇 Fast |\n",
    "| **Resource Usage** | High | Medium | 🥇 Low |\n",
    "| **Stability** | 🥇 Perfect | 🥇 Excellent | ⚠️ Inconsistent |\n",
    "| **Production Ready** | 🥇 YES | 🥇 YES | ⚠️ Needs improvement |\n",
    "\n",
    "### **Technical Learnings**\n",
    "\n",
    "1. **AST Breakthrough**: Audio Spectrogram Transformer achieved research-grade perfect performance\n",
    "2. **Transformer Effectiveness**: All models showed exceptional training performance\n",
    "3. **Generalization Gap**: Training metrics don't always predict real-world performance (HuBERT)\n",
    "4. **Data Efficiency**: Perfect results achieved with just 4% of the original dataset\n",
    "5. **Apple Silicon Optimization**: MPS acceleration provided significant performance benefits\n",
    "\n",
    "### **Production Recommendations**\n",
    "\n",
    "1. **Primary Choice**: **AST** - Perfect performance across all metrics\n",
    "2. **Backup Option**: **Wav2Vec2** - Excellent performance with lower resource requirements\n",
    "3. **Development**: **HuBERT** - Fast training but needs additional work for robust deployment\n",
    "\n",
    "---\n",
    "\n",
    "**Project Status**: ✅ **Successfully Completed**  \n",
    "**Champion Model**: AST (100% accuracy)  \n",
    "**Deployment Ready**: Yes  \n",
    "**Documentation**: Complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔗 Quick Links\n",
    "\n",
    "- **📁 Models**: `/models/` directory\n",
    "- **📊 Results**: `/results/` directory  \n",
    "- **🔊 Test Sounds**: `/sounds/` directory\n",
    "- **💻 Source Code**: `/src/` directory\n",
    "- **📋 Task Details**: `/task/capstone-task.md`\n",
    "- **📖 Documentation**: `/README.md`\n",
    "\n",
    "---\n",
    "\n",
    "*This notebook provides a comprehensive overview of the drone sound recognition capstone project, showcasing the successful implementation and evaluation of multiple state-of-the-art transformer models for audio classification, with AST achieving perfect performance.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
